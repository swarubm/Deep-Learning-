{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqfwMm4Sq13pIRN5OBCPlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarubm/Deep-Learning-/blob/main/DL08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Write a program to read a dataset of text reviews. Classify the reviews as positive or negative."
      ],
      "metadata": {
        "id": "gBDh35TfZx9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FfDSLYCZsKY",
        "outputId": "92693166-ed72-47ef-fbce-e5aee8284ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Loading the IMDb dataset and preprocessing...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training samples: 25000, Test samples: 25000\n",
            "\n",
            "Building model...\n",
            "\n",
            "Starting model training...\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 109ms/step - accuracy: 0.6474 - loss: 0.6171 - val_accuracy: 0.8536 - val_loss: 0.3549\n",
            "Epoch 2/2\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 115ms/step - accuracy: 0.8889 - loss: 0.2831 - val_accuracy: 0.8628 - val_loss: 0.3280\n",
            "\n",
            "Evaluating model on test set...\n",
            "Test Accuracy: 0.8567, Test Loss: 0.3314\n",
            "\n",
            "Classifying the first five test reviews with their actual text:\n",
            "\n",
            "Review #1:\n",
            "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\n",
            "Actual label: negative\n",
            "Predicted label: negative\n",
            "\n",
            "Review #2:\n",
            "<START> this film requires a lot of patience because it focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances <UNK> the sandy dennis character apartment but the film builds to a disturbing climax br br the characters create an atmosphere <UNK> with sexual tension and psychological <UNK> it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the\n",
            "Actual label: positive\n",
            "Predicted label: positive\n",
            "\n",
            "Review #3:\n",
            "<START> many animation buffs consider <UNK> <UNK> the great forgotten genius of one special branch of the art puppet animation which he invented almost single <UNK> and as it happened almost accidentally as a young man <UNK> was more interested in <UNK> than the cinema but his <UNK> attempt to film two <UNK> <UNK> fighting led to an unexpected breakthrough in film making when he realized he could <UNK> movement by <UNK> beetle <UNK> and <UNK> them one frame at a time this discovery led to the production of amazingly elaborate classic short the <UNK> revenge which he made in\n",
            "Actual label: positive\n",
            "Predicted label: positive\n",
            "\n",
            "Review #4:\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# Parameters\n",
        "vocab_size = 10000\n",
        "max_length = 200\n",
        "# Helper to convert encoded review back to text\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index_word = {v+3: k for k, v in word_index.items()}\n",
        "index_word[0] = \"<PAD>\"\n",
        "index_word[1] = \"<START>\"\n",
        "index_word[2] = \"<UNK>\"\n",
        "index_word[3] = \"<UNUSED>\"\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([index_word.get(i, \"?\") for i in encoded_review])\n",
        "print(\"Loading the IMDb dataset and preprocessing...\")\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_length)\n",
        "print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n",
        "print(\"\\nBuilding model...\")\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n",
        "tf.keras.layers.LSTM(16),\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "x_train, y_train,\n",
        "epochs=2,\n",
        "batch_size=128,\n",
        "validation_split=0.1,\n",
        "verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating model on test set...\")\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")\n",
        "print(\"\\nClassifying the first five test reviews with their actual text:\")\n",
        "y_pred = (model.predict(x_test[:5], verbose=0) > 0.5).astype(int).flatten()\n",
        "for i in range(5):\n",
        "    print(f\"\\nReview #{i+1}:\")\n",
        "    print(decode_review(tf.keras.datasets.imdb.load_data(num_words=vocab_size)[1][0][i][:100])\n",
        ")\n",
        "    print(f\"Actual label: {'positive' if y_test[i] else 'negative'}\")\n",
        "    print(f\"Predicted label: {'positive' if y_pred[i] else 'negative'}\")\n",
        "print(\"\\nDone.\")"
      ]
    }
  ]
}